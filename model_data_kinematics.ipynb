{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the kinematic feature extraction code on Modelled Data\n",
    "\n",
    "### Step 0: Make the modelled data\n",
    "### Step 1: Plot and visualized what the expected results of modelled data are\n",
    "### Step 2: Run the kinematic extraction code on the modelled data \n",
    "### Step 3: Plot the extracted kinematics for the modelled data\n",
    "### Step 4: comapred the expectation and the results and make sure kinematic code works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from cv2 import VideoWriter, VideoWriter_fourcc\n",
    "import pandas as pd\n",
    "#import torch\n",
    "from scipy import signal, ndimage, spatial\n",
    "from scipy.signal import correlate\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import math \n",
    "#from signal_alignment import phase_align, chisqr_align\n",
    "from scipy.interpolate import interp1d\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import spearmanr\n",
    "from plot_kinematics_basic import plot_kinematics \n",
    "\n",
    "import get_onsets_basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Make the modelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING A MODEL LOOKUP TABLE \n",
    "input_csv = r\"/Users/denizjafari/documents/CODE/ClinicalScore/ClinicalScore/Test_Table.csv\"\n",
    "out_path = r\"/Users/denizjafari/documents/CODE/ClinicalScore/ClinicalScore/DataModeling\"\n",
    "csv_name = \"model_lookup.csv\"\n",
    "\n",
    "model_lookup = pd.DataFrame()\n",
    "from_example = pd.read_csv(input_csv)\n",
    "\n",
    "try:\n",
    "    from_example = from_example.drop(['Unnamed: 0'], axis=1)\n",
    "    from_example.loc[0][['landmarks']] = r\"/Users/denizjafari/documents/CODE/ClinicalScore/ClinicalScore/DataModeling/NF000_02_BBP_NORMAL_landmarksFiltered3D.csv\"\n",
    "    from_example.loc[0][['landmarks_table']] = r\"/Users/denizjafari/documents/CODE/ClinicalScore/ClinicalScore/DataModeling/NF000_02_BBP_NORMAL_video.Table\"\n",
    "    from_example.loc[0][['rest']] = r\"/Users/denizjafari/documents/CODE/ClinicalScore/ClinicalScore/DataModeling/NF000_02_RST_REST_landmarksFiltered3D.csv\"\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "from_example.to_csv(os.path.join(out_path, csv_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "\n",
    "# Used to extract the patient type from the landmark file name\n",
    "ids = {\n",
    "    \"stroke\": [\"OP\", \"S\"],\n",
    "    \"healthy\": [\"N\"],\n",
    "    \"als\": [\"A\"]\n",
    "}\n",
    "\n",
    "# Defines which metric calculator to use based on the 'metric_type' argument\n",
    "metric_calc_map = {\n",
    "    \"orofacial_features\": ClinicalMetrics,\n",
    "    \"orofacial_signals\": ClinicalSignals\n",
    "}\n",
    "\n",
    "\n",
    "def compute_metrics(inputs, out_path, metrics_type = 'orofacial_features'):\n",
    "    \"\"\"\n",
    "    Computes the metrics for every file in the data csv\n",
    "    :param inputs: A dataframe with columns: csv_path, rep_{}_start,\n",
    "                                                       rep_{}_end\n",
    "    :param out_path: A path to a csv to store the metric data in\n",
    "    \"\"\"\n",
    "    # Key is task name and value is all repetitions of the task\n",
    "    metric_frames: Dict[str, List[pd.DataFrame]] = {}\n",
    "    for index, row in inputs.iterrows():\n",
    "        # Read all data from the input dataframe\n",
    "        try:\n",
    "            data_path = row['csv_path']\n",
    "            rest_path = row['rest_path']\n",
    "            data_frame = pd.read_csv(data_path)\n",
    "            rest_frame = pd.read_csv(rest_path)\n",
    "            task_type = row['task']\n",
    "            subject_id = row['subject']\n",
    "            subject_type = row['type']\n",
    "        except KeyError:\n",
    "            raise KeyError(\"Input csv must contain 'csv_path', 'rest_path', 'rest_table_path' \\\n",
    "            'task', 'subject', and 'type' columns. \\nFurthermore, 'csv_path' \\\n",
    "            and 'rest_path' must be files on the disk.\")\n",
    "        print(\"Starting:\", data_path, \"with\", subject_type, \"patients\")\n",
    "        rep_ranges = []\n",
    "        rep_i = 1\n",
    "        # Grab data about the start and end of repetitions\n",
    "        while f\"rep_{rep_i}_start\" in row and f\"rep_{rep_i}_end\" in row:\n",
    "            try:\n",
    "                start_val = row[f\"rep_{rep_i}_start\"]\n",
    "                end_val = row[f\"rep_{rep_i}_end\"]\n",
    "                rep_ranges.append(range(int(start_val), int(end_val)))\n",
    "            except ValueError as e:\n",
    "                pass\n",
    "            rep_i += 1\n",
    "        rep_i -= 1\n",
    "\n",
    "        # Calculate metrics\n",
    "        metric_calc = metric_calc_map[metrics_type](data_frame, rest_frame)\n",
    "\n",
    "        metric_frame = None\n",
    "        for rep_range in rep_ranges:\n",
    "            metrics = metric_calc.compute_metrics(active_frames=rep_range)\n",
    "            if metric_frame is None:\n",
    "                metric_frame = metrics\n",
    "            else:\n",
    "                metric_frame = pd.concat([metric_frame, metrics], ignore_index=True)\n",
    "        rep_nums = list(range(1, rep_i+1))\n",
    "\n",
    "        # Insert metadata to final csv\n",
    "        metric_frame.insert(0, 'rep', pd.Series(rep_nums))\n",
    "        metric_frame.insert(0, 'type', pd.Series(np.full(rep_i, int(not(subject_type == \"healthy\")))))\n",
    "        metric_frame.insert(0, 'task', pd.Series(np.full(rep_i, task_type)))\n",
    "        metric_frame.insert(0, 'subject_id', pd.Series(np.full(rep_i, subject_id)))\n",
    "        try:\n",
    "            metric_frames[task_type].append(metric_frame)\n",
    "        except KeyError:\n",
    "            metric_frames[task_type] = [metric_frame]\n",
    "\n",
    "    # save data to disk\n",
    "    for task, metrics in metric_frames.items():\n",
    "        csv_name = \"{}_metric_output_{}.csv\".format(metrics_type,task)\n",
    "        \n",
    "        all_metrics_frame = pd.concat(metrics, ignore_index=True)\n",
    "\n",
    "        \n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)\n",
    "        all_metrics_frame.to_csv(os.path.join(out_path, csv_name))\n",
    "        \n",
    "    print(f\"Saved metrics to {os.path.abspath(out_path)}\")\n",
    "    return metric_frames\n",
    "\n",
    "\n",
    "\n",
    "def compute_signals(inputs, out_path, metrics_type = 'orofacial_signals'):\n",
    "    \"\"\"\n",
    "    Computes the metrics for every file in the data csv\n",
    "    :param inputs: A dataframe with columns: csv_path, rep_{}_start,\n",
    "                                                       rep_{}_end\n",
    "    :param out_path: A path to a csv to store the metric data in\n",
    "    \"\"\"\n",
    "    # Key is task name and value is all repetitions of the task\n",
    "    metric_frames: Dict[str, List[pd.DataFrame]] = {}\n",
    "    for index, row in inputs.iterrows():\n",
    "        # Read all data from the input dataframe\n",
    "        try:\n",
    "            data_path = row['csv_path']\n",
    "            rest_path = row['rest_path']\n",
    "            data_frame = pd.read_csv(data_path)\n",
    "            rest_frame = pd.read_csv(rest_path)\n",
    "            task_type = row['task']\n",
    "            subject_id = row['subject']\n",
    "            subject_type = row['type']\n",
    "        except KeyError:\n",
    "            raise KeyError(\"Input csv must contain 'csv_path', 'rest_path', 'rest_table_path' \\\n",
    "            'task', 'subject', and 'type' columns. \\nFurthermore, 'csv_path' \\\n",
    "            and 'rest_path' must be files on the disk.\")\n",
    "        print(\"Starting:\", data_path, \"with\", subject_type, \"patients\")\n",
    "        rep_ranges = []\n",
    "        rep_i = 1\n",
    "        # Grab data about the start and end of repetitions\n",
    "        while f\"rep_{rep_i}_start\" in row and f\"rep_{rep_i}_end\" in row:\n",
    "            try:\n",
    "                start_val = row[f\"rep_{rep_i}_start\"]\n",
    "                end_val = row[f\"rep_{rep_i}_end\"]\n",
    "                rep_ranges.append(range(int(start_val), int(end_val)))\n",
    "            except ValueError as e:\n",
    "                pass\n",
    "            rep_i += 1\n",
    "        rep_i -= 1\n",
    "\n",
    "        # Calculate metrics\n",
    "        metric_calc = metric_calc_map[metrics_type](data_frame, rest_frame)\n",
    "\n",
    "        metric_frame = None\n",
    "        \n",
    "        for rep_range in rep_ranges:\n",
    "            \n",
    "            metrics = metric_calc.compute_metrics(active_frames=rep_range)\n",
    "            metrics.insert(0, 'Time_Stamp', data_frame.loc[rep_range]['Time_Stamp (s)'].values)\n",
    "            metrics.insert(0, 'type', pd.Series(np.full(len(metrics), int(not(subject_type == \"healthy\")))))\n",
    "            metrics.insert(0, 'task', pd.Series(np.full(len(metrics), task_type)))\n",
    "            metrics.insert(0, 'rep', pd.Series(np.full(len(metrics), rep_ranges.index(rep_range))))\n",
    "            metrics.insert(0, 'subject_id', pd.Series(np.full(len(metrics), subject_id)))\n",
    "            \n",
    "            \n",
    "            if metric_frame is None:\n",
    "                metric_frame = metrics\n",
    "            else:\n",
    "                metric_frame = pd.concat([metric_frame, metrics], ignore_index=True)\n",
    "      \n",
    "\n",
    "        # Insert metadata to final csv\n",
    "        \n",
    "        \n",
    "        \n",
    "        try:\n",
    "            metric_frames[task_type].append(metric_frame)\n",
    "        except KeyError:\n",
    "            metric_frames[task_type] = [metric_frame]\n",
    "\n",
    "    # save data to disk\n",
    "    for task, metrics in metric_frames.items():\n",
    "        csv_name = \"{}_metric_output_{}.csv\".format(metrics_type,task)\n",
    "        \n",
    "        all_metrics_frame = pd.concat(metrics, ignore_index=True)\n",
    "\n",
    "        \n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)\n",
    "        all_metrics_frame.to_csv(os.path.join(out_path, csv_name))\n",
    "        \n",
    "    print(f\"Saved metrics to {os.path.abspath(out_path)}\")\n",
    "    return metric_frames\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(input_csv, output_folder, metric_type):\n",
    "    analysis_csv = pd.DataFrame()\n",
    "    files = pd.read_csv(input_csv)\n",
    "    for i, row in files.iterrows():\n",
    "        # Construct a dataframe with the information necessary for processing\n",
    "        landmark_path = os.path.abspath(row[\"landmarks\"])\n",
    "        landmark_file_name = os.path.basename(landmark_path)\n",
    "        table_path = os.path.abspath(row[\"landmarks_table\"])\n",
    "        table_file_name = os.path.basename(table_path)\n",
    "        rest_path = os.path.abspath(row[\"rest\"])\n",
    "        rest_file_name = os.path.basename(table_path)\n",
    "        print(landmark_path)\n",
    "        print()\n",
    "        print(rest_path)\n",
    "        print()\n",
    "        print(table_path)\n",
    "\n",
    "        if not os.path.isfile(landmark_path):\n",
    "            raise RuntimeError(\"Landmark path is not a file on disk\")\n",
    "        if not os.path.isfile(rest_path):\n",
    "            raise RuntimeError(\"Rest file is not a file on disk\")\n",
    "        if not os.path.isfile(table_path):\n",
    "            raise RuntimeError(\"Table file is not a file on disk\")\n",
    "\n",
    "        landmark_file_data = landmark_file_name.split(\"_\")\n",
    "        subject = landmark_file_data[0]\n",
    "        subject_type = \"\"\n",
    "        # Check if a user fits into a known subject type\n",
    "        for s_type, prefixes in ids.items():\n",
    "            for prefix in prefixes:\n",
    "                if prefix in subject:\n",
    "                    subject_type = s_type\n",
    "        task = \"_\".join(landmark_file_data[2:4])\n",
    "        parsed_data = pd.DataFrame(columns=[\"csv_path\", \"type\", \"rest_path\", \"subject\", \"task\"])\n",
    "        parsed_data.loc[0] = 0\n",
    "\n",
    "        \n",
    "     \n",
    "        video_info = pd.read_csv(table_path)\n",
    "\n",
    "\n",
    "        parsed_data[\"csv_path\"] = landmark_path\n",
    "        parsed_data[\"rest_path\"] = rest_path\n",
    "        parsed_data[\"type\"] = subject_type\n",
    "        parsed_data[\"subject\"] = subject\n",
    "        parsed_data[\"task\"] = task\n",
    "        for index, row in video_info.iterrows():\n",
    "            parsed_data[f\"rep_{index+1}_start\"] = row[video_info.columns[0]]\n",
    "            parsed_data[f\"rep_{index+1}_end\"] = row[video_info.columns[-1]] \n",
    "        analysis_csv = analysis_csv.append(parsed_data, ignore_index=True, sort=False)\n",
    "\n",
    "\n",
    "    if metric_type == 'orofacial_signals':\n",
    "        compute_signals(analysis_csv, output_folder,metric_type);\n",
    "        \n",
    "    else:\n",
    "        compute_metrics(analysis_csv, output_folder,metric_type);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with mini lookup table of 1 modelled data\n",
    "\n",
    "metric_type = 'orofacial_signals' \n",
    "\n",
    " #csv file with modelled fake landmarks info and the made up .TABLE info\n",
    "input_csv = r\"/Users/denizjafari/documents/CODE/ClinicalScore/ClinicalScore/DataModeling/model_lookup.csv\"\n",
    "#where to store the results\n",
    "output_folder = r\"/Users/denizjafari/documents/CODE/ClinicalScore/ClinicalScore/DataModeling\" \n",
    "save_results(input_csv, output_folder, metric_type)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_type = 'orofacial_features' \n",
    "\n",
    " #csv file with modelled fake landmarks info and the made up .TABLE info\n",
    "input_csv = r\"/Users/denizjafari/documents/CODE/ClinicalScore/ClinicalScore/DataModeling/model_lookup.csv\"\n",
    "#where to store the results\n",
    "output_folder = r\"/Users/denizjafari/documents/CODE/ClinicalScore/ClinicalScore/DataModeling\"\n",
    "save_results(input_csv, output_folder, metric_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ClinicalScore36",
   "language": "python",
   "name": "clinicalscore36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
